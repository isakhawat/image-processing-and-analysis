{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Crepe-Gluon.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6rwYLwcS_Uo",
        "colab_type": "text"
      },
      "source": [
        "# Character-level Convolutional Networks for text Classification\n",
        "\n",
        "## Crepe model implementation with MXNet/Gluon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FGylnztS_Uv",
        "colab_type": "text"
      },
      "source": [
        "This is an implementation of [the crepe model, Character-level Convolutional Networks for Text Classification](https://arxiv.org/abs/1509.01626) using the MXNet Gluon API. That this is the paper we reference throughout the tutorial\n",
        "\n",
        "We are going to perform a **text classification** task, trying to classify Amazon reviews according to the product category they belong to.\n",
        "\n",
        "This work is inspired from a previous collaborative work with [Ilia Karmanov and Miguel Fierro](https://github.com/ilkarman/NLP-Sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syow7UD4S_Ux",
        "colab_type": "text"
      },
      "source": [
        "## Install Guide\n",
        "You need to install [Apache MXNet](http://mxnet.incubator.apache.org/) in order to run this tutorial. The following lines should work in most platform but checkout the [Apache install](http://mxnet.incubator.apache.org/install/index.html) guide for more info, especially if you plan to use GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01ICSP0sS_U1",
        "colab_type": "code",
        "outputId": "fc049a17-e6d1-49de-ab22-7b28e4200f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# GPU install\n",
        "!pip install mxnet-cu90 pandas -q\n",
        "# CPU install\n",
        "!pip install mxnet pandas -q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 488.8MB 32kB/s \n",
            "\u001b[K     |████████████████████████████████| 25.4MB 1.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjVZRGAhS_U_",
        "colab_type": "text"
      },
      "source": [
        "## Data download\n",
        "The dataset has been made available on this website: http://jmcauley.ucsd.edu/data/amazon/, citation of relevant papers:\n",
        "\n",
        "**Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering**\n",
        "R. He, J. McAuley\n",
        "*WWW*, 2016\n",
        "\n",
        "**Image-based recommendations on styles and substitutes**\n",
        "J. McAuley, C. Targett, J. Shi, A. van den Hengel\n",
        "*SIGIR*, 2015\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMg6Q4c6S_VB",
        "colab_type": "text"
      },
      "source": [
        "We are downloading a subset of the reviews, the k-core reviews, where k=5. That means that for each category, the dataset has been trimmed to only contain 5 reviews per individual product, and 5 reviews per user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EE3_UaAS_VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import mxnet as mx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1dCWo3LS_VK",
        "colab_type": "code",
        "outputId": "adea9676-3f7f-4c73-84f0-2ea5cf345eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "base_url = 'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/'\n",
        "prefix = 'reviews_'\n",
        "suffix = '_5.json.gz'\n",
        "folder = 'data'\n",
        "categories = [\n",
        "    'Home_and_Kitchen',\n",
        "    'Books', \n",
        "    'CDs_and_Vinyl', \n",
        "    'Movies_and_TV', \n",
        "    'Cell_Phones_and_Accessories',\n",
        "    'Sports_and_Outdoors', \n",
        "    'Clothing_Shoes_and_Jewelry'\n",
        "]\n",
        "if not os.path.isdir(folder):\n",
        "    os.mkdir(folder)\n",
        "for category in categories:\n",
        "    print(category)\n",
        "    url = base_url+prefix+category+suffix\n",
        "    mx.test_utils.download(url, dirname=folder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Home_and_Kitchen\n",
            "Books\n",
            "CDs_and_Vinyl\n",
            "Movies_and_TV\n",
            "Cell_Phones_and_Accessories\n",
            "Sports_and_Outdoors\n",
            "Clothing_Shoes_and_Jewelry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDa46eTxS_VS",
        "colab_type": "text"
      },
      "source": [
        "## Data Pre-processing\n",
        "We need to perform some pre-processing steps in order to have the data in a format we can use for training (**X**,**Y**)\n",
        "In order to speed up training and balance the dataset we will only use a subset of reviews for each category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVreps3rS_VW",
        "colab_type": "text"
      },
      "source": [
        "### Load the data in memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pzRqyrES_VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_ITEMS_PER_CATEGORY = 250000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYg_rrjnS_Vl",
        "colab_type": "text"
      },
      "source": [
        "Helper functions to read from the .json.gzip files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGgBMG8hS_Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "def parse(path):\n",
        "    g = gzip.open(path, 'rb')\n",
        "    for line in g:\n",
        "        yield eval(line)\n",
        "\n",
        "def get_dataframe(path, num_lines):\n",
        "    i = 0\n",
        "    df = {}\n",
        "    for d in parse(path):\n",
        "        if i > num_lines:\n",
        "            break\n",
        "        df[i] = d\n",
        "        i += 1\n",
        "\n",
        "    return pd.DataFrame.from_dict(df, orient='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XnpwDvTS_V6",
        "colab_type": "text"
      },
      "source": [
        "For each category we load MAX_ITEMS_PER_CATEGORY by randomly sampling the files and shuffling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoxyfsihS_V8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading data from file if exist\n",
        "try:\n",
        "    data = pd.read_pickle('pickleddata.pkl')\n",
        "except:\n",
        "    data = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpF-r0jJS_WE",
        "colab_type": "text"
      },
      "source": [
        "If the data is not available in the pickled file, we create it from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frVRAlLMS_WI",
        "colab_type": "code",
        "outputId": "194e5c79-5267-4ec4-b120-61c8cfdbd0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "if data is None:\n",
        "    data = pd.DataFrame(data={'X':[],'Y':[]})\n",
        "    for index, category in enumerate(categories):\n",
        "        df = get_dataframe(\"{}/{}{}{}\".format(folder, prefix, category, suffix), MAX_ITEMS_PER_CATEGORY)    \n",
        "        # Each review's summary is prepended to the main review text\n",
        "        df = pd.DataFrame(data={'X':(df['summary']+' | '+df['reviewText'])[:MAX_ITEMS_PER_CATEGORY],'Y':index})\n",
        "        data = data.append(df)\n",
        "        print('{}:{} reviews'.format(category, len(df)))\n",
        "\n",
        "    # Shuffle the samples\n",
        "    data = data.sample(frac=1)\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "    # Saving the data in a pickled file\n",
        "    pd.to_pickle(data, 'pickleddata.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Home_and_Kitchen:250000 reviews\n",
            "Books:250000 reviews\n",
            "CDs_and_Vinyl:250000 reviews\n",
            "Movies_and_TV:250000 reviews\n",
            "Cell_Phones_and_Accessories:194439 reviews\n",
            "Sports_and_Outdoors:250000 reviews\n",
            "Clothing_Shoes_and_Jewelry:250000 reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6R_IcpeS_WP",
        "colab_type": "text"
      },
      "source": [
        "Let's visualize the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdx1OXQtS_WR",
        "colab_type": "code",
        "outputId": "cd0fa883-45e7-4262-d39f-06e5913cb847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print('Value counts:\\n',data['Y'].value_counts())\n",
        "for i,cat in enumerate(categories):\n",
        "    print(i, cat)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value counts:\n",
            " 1.0    250000\n",
            "6.0    250000\n",
            "5.0    250000\n",
            "3.0    250000\n",
            "2.0    250000\n",
            "0.0    250000\n",
            "4.0    194439\n",
            "Name: Y, dtype: int64\n",
            "0 Home_and_Kitchen\n",
            "1 Books\n",
            "2 CDs_and_Vinyl\n",
            "3 Movies_and_TV\n",
            "4 Cell_Phones_and_Accessories\n",
            "5 Sports_and_Outdoors\n",
            "6 Clothing_Shoes_and_Jewelry\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Grill press | If you do a LOT of grilling as d...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hy's Story Will Entertain... | Ms. Quinn is a ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Terrifying | I've read mixed reviews of this h...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi | I'm just trying to do this movie justice ...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My New Best Friend | After doing some online r...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   X    Y\n",
              "0  Grill press | If you do a LOT of grilling as d...  0.0\n",
              "1  Hy's Story Will Entertain... | Ms. Quinn is a ...  1.0\n",
              "2  Terrifying | I've read mixed reviews of this h...  3.0\n",
              "3  Hi | I'm just trying to do this movie justice ...  3.0\n",
              "4  My New Best Friend | After doing some online r...  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny5y6Lw9S_WX",
        "colab_type": "text"
      },
      "source": [
        "### Creating the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hItTog9S_WY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "from mxnet import nd, autograd, gluon\n",
        "from mxnet.gluon.data import ArrayDataset\n",
        "from mxnet.gluon.data import DataLoader\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxO3YJpTS_Wg",
        "colab_type": "text"
      },
      "source": [
        "Setting up the parameters for the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko4USkPtS_Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ALPHABET = list(\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+ =<>()[]{}\") # The 69 characters as specified in the paper\n",
        "ALPHABET_INDEX = {letter: index for index, letter in enumerate(ALPHABET)} # { a: 0, b: 1, etc}\n",
        "FEATURE_LEN = 1014 # max-length in characters for one document\n",
        "NUM_WORKERS = max(multiprocessing.cpu_count() - 3, 1)# number of workers used in the data loading\n",
        "BATCH_SIZE = 128 # number of documents per batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efRKk2kYS_Wq",
        "colab_type": "text"
      },
      "source": [
        "According to the paper, each document needs to be encoded in the following manner:\n",
        "    - Truncate to 1014 characters\n",
        "    - Reverse the string\n",
        "    - One-hot encode based on the alphabet\n",
        "    \n",
        "The following `encode` function does this for us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qXkbXM8S_Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(text):\n",
        "    encoded = np.zeros([len(ALPHABET), FEATURE_LEN], dtype='float32')\n",
        "    review = text.lower()[:FEATURE_LEN-1:-1]\n",
        "    i = 0\n",
        "    for letter in text:\n",
        "        if i >= FEATURE_LEN:\n",
        "            break;\n",
        "        if letter in ALPHABET_INDEX:\n",
        "            encoded[ALPHABET_INDEX[letter]][i] = 1\n",
        "        i += 1\n",
        "    return encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9l2_xYTS_W1",
        "colab_type": "text"
      },
      "source": [
        "The MXNet DataSet and DataLoader API lets you create different worker to pre-fetch the data and encode it the way you want, in order to prevent your GPU from starving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UVjPb4ZS_W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(x, y):\n",
        "    return encode(x), y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaheJZmbS_W8",
        "colab_type": "text"
      },
      "source": [
        "We split our data into a training and a testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM4hRRngS_W-",
        "colab_type": "code",
        "outputId": "dfb69b51-a2da-46fe-c345-3e0cb7286896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "split = 0.8\n",
        "split_index = int(split*len(data))\n",
        "train_data_X = data['X'][:split_index].as_matrix()\n",
        "train_data_Y = data['Y'][:split_index].as_matrix()\n",
        "test_data_X = data['X'][split_index:].as_matrix()\n",
        "test_data_Y = data['Y'][split_index:].as_matrix()\n",
        "train_dataset = ArrayDataset(train_data_X, train_data_Y).transform(transform)\n",
        "test_dataset = ArrayDataset(test_data_X, test_data_Y).transform(transform)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmMKw4mSS_XD",
        "colab_type": "text"
      },
      "source": [
        "Creating the training and testing dataloader, with NUM_WORKERS set to the number of CPU core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgy2m1MCS_XG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, last_batch='rollover')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOmPxns4S_XO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, last_batch='rollover')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8x84I7PS_XV",
        "colab_type": "text"
      },
      "source": [
        "## Creation of the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCGFJUMvS_XY",
        "colab_type": "text"
      },
      "source": [
        "The context will define where the training takes place, on the CPU or on the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzgzK96TS_Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx = mx.gpu() if mx.context.num_gpus() else mx.cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIDQTeBLS_Xu",
        "colab_type": "text"
      },
      "source": [
        "We create the network following the instructions describe in the paper, using the small feature and small output units configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sMmpvl9S_X0",
        "colab_type": "text"
      },
      "source": [
        "![img](data/diagram.png)\n",
        "![img](data/convolutional_layers.png)\n",
        "![img](data/dense_layer.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNhTkoirS_X2",
        "colab_type": "text"
      },
      "source": [
        "Based on the paper we set the following parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv98-YdwS_X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_FILTERS = 256 # number of convolutional filters per convolutional layer\n",
        "NUM_OUTPUTS = len(categories) # number of classes\n",
        "FULLY_CONNECTED = 1024 # number of unit in the fully connected dense layer\n",
        "DROPOUT_RATE = 0.5 # probability of node drop out\n",
        "LEARNING_RATE = 0.001 # learning rate of the gradient\n",
        "MOMENTUM = 0.9 # momentum of the gradient\n",
        "WDECAY = 0.00001 # regularization term to limit size of weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR6hPY5oS_YB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = gluon.nn.HybridSequential()\n",
        "with net.name_scope():\n",
        "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=7, activation='relu'))\n",
        "    net.add(gluon.nn.MaxPool1D(pool_size=3, strides=3))\n",
        "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=7, activation='relu'))\n",
        "    net.add(gluon.nn.MaxPool1D(pool_size=3, strides=3))\n",
        "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.Conv1D(channels=NUM_FILTERS, kernel_size=3, activation='relu'))\n",
        "    net.add(gluon.nn.MaxPool1D(pool_size=3, strides=3))\n",
        "    net.add(gluon.nn.Flatten())\n",
        "    net.add(gluon.nn.Dense(FULLY_CONNECTED, activation='relu'))\n",
        "    net.add(gluon.nn.Dropout(DROPOUT_RATE))\n",
        "    net.add(gluon.nn.Dense(FULLY_CONNECTED, activation='relu'))\n",
        "    net.add(gluon.nn.Dropout(DROPOUT_RATE))\n",
        "    net.add(gluon.nn.Dense(NUM_OUTPUTS))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8sGslxqS_YG",
        "colab_type": "code",
        "outputId": "f3fe345b-7532-487d-e144-114baa3f44db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HybridSequential(\n",
            "  (0): Conv1D(None -> 256, kernel_size=(7,), stride=(1,), Activation(relu))\n",
            "  (1): MaxPool1D(size=(3,), stride=(3,), padding=(0,), ceil_mode=False, global_pool=False, pool_type=max, layout=NCW)\n",
            "  (2): Conv1D(None -> 256, kernel_size=(7,), stride=(1,), Activation(relu))\n",
            "  (3): MaxPool1D(size=(3,), stride=(3,), padding=(0,), ceil_mode=False, global_pool=False, pool_type=max, layout=NCW)\n",
            "  (4): Conv1D(None -> 256, kernel_size=(3,), stride=(1,), Activation(relu))\n",
            "  (5): Conv1D(None -> 256, kernel_size=(3,), stride=(1,), Activation(relu))\n",
            "  (6): Conv1D(None -> 256, kernel_size=(3,), stride=(1,), Activation(relu))\n",
            "  (7): Conv1D(None -> 256, kernel_size=(3,), stride=(1,), Activation(relu))\n",
            "  (8): MaxPool1D(size=(3,), stride=(3,), padding=(0,), ceil_mode=False, global_pool=False, pool_type=max, layout=NCW)\n",
            "  (9): Flatten\n",
            "  (10): Dense(None -> 1024, Activation(relu))\n",
            "  (11): Dropout(p = 0.5, axes=())\n",
            "  (12): Dense(None -> 1024, Activation(relu))\n",
            "  (13): Dropout(p = 0.5, axes=())\n",
            "  (14): Dense(None -> 7, linear)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0DaxAw9S_YM",
        "colab_type": "text"
      },
      "source": [
        "Here we define whether we load a pre-trained version of the model and [hybridize the network](https://mxnet.incubator.apache.org/tutorials/gluon/hybrid.html) for speed improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kGxN-5hS_YN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hybridize = True # for speed improvement, compile the network but no in-depth debugging possible\n",
        "load_params = True # Load pre-trained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e5cBRcoS_YU",
        "colab_type": "text"
      },
      "source": [
        "### Parameter initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqKF-atBS_YW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_params:\n",
        "    net.load_parameters('model/crepe_gluon_epoch6.params', ctx=ctx)\n",
        "else:\n",
        "    net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099_vDf1S_Ya",
        "colab_type": "text"
      },
      "source": [
        "### Hybridization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUa5k_iYS_Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if hybridize:\n",
        "    net.hybridize(static_alloc=True, static_shape=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1AMLSiES_Yh",
        "colab_type": "text"
      },
      "source": [
        "### Softmax cross-entropy Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbxnoiC9S_Yk",
        "colab_type": "text"
      },
      "source": [
        "We are in a multi-class classification problem, so we use the [Softmax Cross entropy loss](https://deepnotes.io/softmax-crossentropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5pLRuD5S_Ym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S950jkgoS_Yt",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgSSGI26S_Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
        "                        {'learning_rate': LEARNING_RATE, \n",
        "                         'wd':WDECAY, \n",
        "                         'momentum':MOMENTUM})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8QrKD5bS_Y3",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saQJp5xeS_Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_accuracy(data_iterator, net):\n",
        "    acc = mx.metric.Accuracy()\n",
        "    for i, (data, label) in enumerate(data_iterator):\n",
        "        data = data.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        output = net(data)\n",
        "        prediction = nd.argmax(output, axis=1)\n",
        "        acc.update(preds=prediction, labels=label)\n",
        "    return acc.get()[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiORmZTES_Y_",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop\n",
        "We loop through the batches given by the data_loader. These batches have been asynchronously fetched by the workers.\n",
        "\n",
        "After an epoch, we measure the test_accuracy and save the parameters of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHYp6gJXS_ZB",
        "colab_type": "code",
        "outputId": "68d0df6a-802a-4c5b-94f7-2ebe217b9e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "start_epoch = 6\n",
        "number_epochs = 7\n",
        "smoothing_constant = .01\n",
        "for e in range(start_epoch, number_epochs):\n",
        "    for i, (review, label) in enumerate(train_dataloader):\n",
        "        review = review.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        with autograd.record():\n",
        "            output = net(review)\n",
        "            loss = softmax_cross_entropy(output, label)\n",
        "        loss.backward()\n",
        "        trainer.step(review.shape[0])\n",
        "        \n",
        "        # moving average of the loss\n",
        "        curr_loss = nd.mean(loss)\n",
        "        moving_loss = (curr_loss if (i == 0) \n",
        "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
        "\n",
        "        if (i%200 == 0):\n",
        "            print('Batch {}: Instant loss {:.4f}, Moving loss {:.4f}'.format(i,curr_loss.asscalar(), moving_loss.asscalar()))\n",
        "\n",
        "    test_accuracy = evaluate_accuracy(test_dataloader, net)\n",
        "    #Save the model using the gluon params format\n",
        "    net.save_parameters('crepe_epoch_{}_test_acc_{}.params'.format(e,int(test_accuracy*10000)/100))\n",
        "    print(\"Epoch {}. Loss: {:.4f}, Test_acc {:.4f}\".format(e, moving_loss.asscalar(), test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-2c023d7fd541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_cached_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m_call_cached_op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             cargs = [args[i] if is_arg else i.data()\n\u001b[0;32m--> 811\u001b[0;31m                      for is_arg, i in self._cached_op_args]\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDeferredInitializationError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred_infer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             cargs = [args[i] if is_arg else i.data()\n\u001b[0;32m--> 811\u001b[0;31m                      for is_arg, i in self._cached_op_args]\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDeferredInitializationError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred_infer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    541\u001b[0m                                \u001b[0;34m\"because its storage type is %s. Please use row_sparse_data() \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                                \"instead.\" % (self.name, str(ctx), self._stype))\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_and_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36m_check_and_get\u001b[0;34m(self, arr_list, ctx)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;34m\"with Block.collect_params() instead of Block.params \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;34m\"because the later does not include Parameters of \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \"nested child Blocks\"%(self.name))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_row_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parameter 'hybridsequential2_conv0_weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZiF3UJgS_Zc",
        "colab_type": "text"
      },
      "source": [
        "### Export to the symbolic format\n",
        "The `save_params()` method works for models trained in Gluon. \n",
        "\n",
        "However the `export()` function, exports it to a format usable in the symbolic API, if you wanted to use in C++ or Scala for example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC4Inel9S_Zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.export('crepe', epoch=number_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcbgaLWS_Zv",
        "colab_type": "text"
      },
      "source": [
        "### Random testing\n",
        "\n",
        "Let's randomly pick a few reviews and see how the classifier does!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOhB4rb2S_Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "for i in range(50):\n",
        "    index = random.randint(1, len(data))\n",
        "    review = data['X'][index]\n",
        "    label = categories[int(data['Y'][index])]\n",
        "    print(review)\n",
        "    print('\\nCategory: {}\\n'.format(label))\n",
        "    encoded = nd.array([encode(review)], ctx=ctx)\n",
        "    output = net(encoded)\n",
        "    predicted = categories[np.argmax(output[0].asnumpy())]\n",
        "    if predicted == label:\n",
        "          print('Correct')\n",
        "    else:\n",
        "          print('Incorrectly predicted {}'.format(predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK1U8qN5S_Z2",
        "colab_type": "text"
      },
      "source": [
        "### Manual Testing\n",
        "We can also write our own reviews, encode them and see what the model predicts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88g-p-HMS_Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_title = \"Good stuff\"\n",
        "review = \"This album is definitely better than the previous one\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-R3mGfIQS_Z6",
        "colab_type": "code",
        "outputId": "3f74db49-de4b-4111-c2fd-917b393204f3",
        "colab": {}
      },
      "source": [
        "print(review_title)\n",
        "print(review + '\\n')\n",
        "encoded = nd.array([encode(review + \" | \" + review_title)], ctx=ctx)\n",
        "output = net(encoded)\n",
        "softmax = nd.exp(output) / nd.sum(nd.exp(output))[0]\n",
        "predicted = categories[np.argmax(output[0].asnumpy())]\n",
        "print('Predicted: {}\\n'.format(predicted))\n",
        "for i, val in enumerate(categories):\n",
        "    print(val, float(int(softmax[0][i].asnumpy()*1000)/10), '%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good stuff\n",
            "This album is definitely better than the previous one\n",
            "\n",
            "Predicted: CDs_and_Vinyl\n",
            "\n",
            "Home_and_Kitchen 0.0 %\n",
            "Books 0.0 %\n",
            "CDs_and_Vinyl 99.2 %\n",
            "Movies_and_TV 0.5 %\n",
            "Cell_Phones_and_Accessories 0.1 %\n",
            "Sports_and_Outdoors 0.0 %\n",
            "Clothing_Shoes_and_Jewelry 0.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC81pjy0S_Z-",
        "colab_type": "text"
      },
      "source": [
        "# Model Deployment\n",
        "\n",
        "Head over to the `model/` folder and have a look at the README.md to learn how you can deploy this pre-trained model to MXNet Model Server. You can then package the API in a docker container for cloud deployment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agKrdrUAS_Z_",
        "colab_type": "text"
      },
      "source": [
        "An interactive live demo is available [here](https://thomasdelteil.github.io/CNN_NLP_MXNet/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4tPrXWNS_aB",
        "colab_type": "text"
      },
      "source": [
        "[![img](data/live_demo.png)](https://thomasdelteil.github.io/CNN_NLP_MXNet/)"
      ]
    }
  ]
}